import torch
from transformers import SamModel, SamProcessor
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix
import cv2
import os
import warnings
from sklearn.preprocessing import Binarizer

warnings.filterwarnings('ignore')

class MoS2Analyzer:
    FEATURE_LABELS = {
        0: "Single Layer",
        1: "Multi Layer",
        2: "Substrate",
        3: "Defects",
        4: "Edge Sites"
    }

    def __init__(self):
        print("Loading SAM model...")
        self.sam_model = SamModel.from_pretrained("facebook/sam-vit-huge")
        self.sam_processor = SamProcessor.from_pretrained("facebook/sam-vit-huge")
        if torch.cuda.is_available():
            self.sam_model.to("cuda")
        print("Models loaded successfully!")

    def load_and_verify_image(self, image_path):
        if not os.path.exists(image_path):
            raise FileNotFoundError(f"Image file not found at: {image_path}")
        image = cv2.imread(image_path)
        if image is None:
            raise ValueError(f"Failed to load image at: {image_path}")
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        plt.imshow(image)
        plt.title("Loaded Image")
        plt.show()
        return image

    def process_image(self, image, prompt_points=None):
        try:
            h, w = image.shape[:2]
            pixel_points, labels = [], []

            if prompt_points is None:
                prompt_points = {0: [[0.5, 0.5]]}  # Default center point

            for feature, points in prompt_points.items():
                for x, y in points:
                    pixel_points.append([int(x * w), int(y * h)])
                    labels.append(list(prompt_points.keys()).index(feature))

            inputs = self.sam_processor(image, input_points=[pixel_points], return_tensors="pt")
            if torch.cuda.is_available():
                inputs = {k: v.to("cuda") for k, v in inputs.items()}

            outputs = self.sam_model(**inputs)

            if outputs.pred_masks is None or outputs.pred_masks.numel() == 0:
                raise ValueError("No masks were generated by the SAM model.")

            # Apply sigmoid to convert logits to probabilities
            masks = torch.sigmoid(outputs.pred_masks).squeeze().cpu().detach().numpy()
            if len(masks.shape) == 2:
                masks = np.expand_dims(masks, axis=0)

            return masks, labels
        except Exception as e:
            print(f"Error in process_image: {str(e)}")
            raise

    def apply_rgb_perturbation(self, image, channel, magnitude=50):
        perturbed = image.copy()
        noise = np.random.normal(0, magnitude, image.shape[:2])
        perturbed[:, :, channel] = np.clip(perturbed[:, :, channel] + noise, 0, 255)
        return perturbed.astype(np.uint8)

    def analyze_perturbations(self, image_path):
        """Analyzes how perturbing each RGB channel affects the segmentation mask."""
        try:
            image = self.load_and_verify_image(image_path)
            base_masks, labels = self.process_image(image)

            fig, axes = plt.subplots(2, 3, figsize=(14, 8))
            axes[0, 0].imshow(image)
            axes[0, 0].set_title("Original Image")
            axes[0, 0].axis('off')

            threshold = 0.5  # Binarization threshold

            for channel in range(3):
                perturbed_image = self.apply_rgb_perturbation(image, channel)
                perturbed_masks, _ = self.process_image(perturbed_image)
                
                # Binarizing the masks
                base_bin = (base_masks > threshold).astype(int).flatten()
                perturbed_bin = (perturbed_masks > threshold).astype(int).flatten()

                # Compute Confusion Matrix
                cm = confusion_matrix(base_bin, perturbed_bin)

                # Plot results
                axes[0, channel + 1].imshow(perturbed_image)
                axes[0, channel + 1].set_title(f"Perturbed (Channel {channel})")
                axes[0, channel + 1].axis('off')

                sns.heatmap(cm, annot=True, fmt="d", ax=axes[1, channel], cmap="Blues")
                axes[1, channel].set_title(f"Confusion Matrix (Channel {channel})")

            plt.tight_layout()
            plt.show()
        except Exception as e:
            print(f"Error in analyze_perturbations: {str(e)}")

if __name__ == "__main__":
    analyzer = MoS2Analyzer()
    image_path = "FILE-PATH"
    analyzer.analyze_perturbations(image_path)
